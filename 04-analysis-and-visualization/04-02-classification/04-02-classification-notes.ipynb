{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a set of notes on this exercise\n",
    "* These were created during office hours. \n",
    "* You are free to replace your workbook with this one -- or not. \n",
    "* Remember that only the workbook named `Classification.ipynb` gets transmitted to me. \n",
    "\n",
    "# Classification\n",
    "\n",
    "* You're probably aware of some parametric prediction methods, e.g., linear regression.  \n",
    "* Let's study a non-parametric prediction method. \n",
    "* The goal of this method: classify something into one of a discrete number of types. \n",
    "* This is also known as 'supervised learning'. \n",
    "\n",
    "# The simplest classification problem\n",
    "* Given an existing spreadsheet of descriptions of items and their categories, \n",
    "* Predict the category for a new line of description, \n",
    "* Based only upon the existing data. \n",
    "* There are many, many ways to do this. \n",
    "\n",
    "# An example: \n",
    "* Given an existing spreadsheet of dimensions of irises (flowers), and expert classifications of each iris into a species, \n",
    "* Predict the species for a new iris based upon its measurements. \n",
    "\n",
    "# Specialized language: \n",
    "* Input data: big table of attributes of irises. \n",
    "* Output: \"target\": a number between 0-2 or 1-3 that determines the species. \n",
    "* Additional information: interpretation of the numbers. \n",
    "\n",
    "# The point of this example: \n",
    "* Learn how we evaluate machine learning as a discipline. \n",
    "* To treat the machine learning process as a \"black box\" that we'll go into in later courses. \n",
    "* To satisfy requirements (preconditions) to make the box work. \n",
    "* To evaluate the output of the black box. \n",
    "\n",
    "# Suspension of disbelief\n",
    "* This is sort of like reading science fiction. \n",
    "* You have something that is \"magic\". \n",
    "* It does something you want. \n",
    "* You want to know how well it does it. \n",
    "* You treat it as an \"oracle\".\n",
    "* You evaluate how well it does. \n",
    "\n",
    "# Scikit-Learn\n",
    "\n",
    "* Scikit-Learn is a major machine learning library that includes many reference data sets. \n",
    "* It has its own formats. \n",
    "* It's important to know how to translate to other formats to accomplish tasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Iris Dataset\n",
    "\n",
    "* There is one dataset that is so well-known that it bears mentioning in any context. \n",
    "* The *iris dataset* consists of a multidimensional array of iris characteristics used in determining species. \n",
    "* Let's explore this dataset and see if we can understand it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "iris\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a special-purpose format. \n",
    "* A class\n",
    "* Implemented as a dictionary. \n",
    "* Intended for testing machine-learning algorithms. \n",
    "* With fields that make sense for that task.\n",
    "* Most entries are arrays in `numpy` format. \n",
    "\n",
    "Let's find out a bit about it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To put this into a DataFrame, you need to interpret the iris object. \n",
    "import pandas as pd\n",
    "idf = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# But this doesn't help at all. \n",
    "* `DataFrames` are a newer concept. \n",
    "* The algorithm is designed to run on the old format. \n",
    "* `DataFrames` don't help.\n",
    "* We really need to understand what a `Bunch` is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important fields in the iris dataset\n",
    "* `iris.data`: a set of feature vectors describing different plants. \n",
    "* `iris.target`: the kind of plant\n",
    "* `iris.feature_names`: the names of columns\n",
    "* `iris.target_names`: the English names of the kinds. \n",
    "\n",
    "# The classification problem\n",
    "* Given what we know about a thing (`iris.data`) \n",
    "* What species is it (`iris.target`)? \n",
    "\n",
    "# How we approach classification: \n",
    "* Take all data into account. \n",
    "* Think of the data as a function from `data` to `target`.\n",
    "* Approximate that function. \n",
    "\n",
    "# Then, if there is a new kind of iris, \n",
    "* Use the function to predict what species it is. \n",
    "\n",
    "# Let's run the demo provided by scikit-learn: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Declare a KNN classifier of a given complexity. The number of neighbors determines runtime.\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "# create a map between data and target. \n",
    "knn.fit(iris['data'], iris['target'])\n",
    "\n",
    "# Provide data whose class labels are to be predicted\n",
    "X = [\n",
    "    [5.9, 1.0, 5.1, 1.8],\n",
    "    [3.4, 2.0, 1.1, 4.8],\n",
    "]\n",
    "\n",
    "# Prints the data provided\n",
    "print(X)\n",
    "\n",
    "# Store predicted class labels of X\n",
    "prediction = knn.predict(X)\n",
    "\n",
    "# Prints the predicted class labels of X\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This, according to the predictor, they're both species 1 of 0-2. \n",
    "\n",
    "* Writing such a predictor is a complex task that we study in COMP 135. \n",
    "* You can read up on it here: https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm\n",
    "\n",
    "For now, suffice it to say that from enough measurements, one can form a prediction \n",
    "from the instances that have been observed so far. This prediction can be accurate or inaccurate \n",
    "based upon the prediction method. \n",
    "\n",
    "# From whence comes accuracy\n",
    "* You would be right to be suspicious of what I just did. \n",
    "* I didn't tell you anything at all about the prediction method. It is an \"oracle\". \n",
    "* How do we know that this worked? \n",
    "\n",
    "# Cross-validation\n",
    "* Cross-validation is a standard technique in machine learning for testing classifiers. \n",
    "* Separate all feature data into 'training' and 'testing' subsets. \n",
    "* Train on the training subset. \n",
    "* Test on the testing subset. \n",
    "* See if you get the correct answers.\n",
    "\n",
    "# The big point\n",
    "* This works no matter what algorithm you are testing. \n",
    "* Does the algorithm work reasonably on questions whose answers are already known? \n",
    "\n",
    "# Let's do this. I'll help.\n",
    "* This is a different kind of exercise. \n",
    "* This is a real cross-validation using random data. \n",
    "* There is no one \"correct\" answer. \n",
    "* I can check your answers for sanity but not for correctness. \n",
    "\n",
    "# How to set up a cross-validation: \n",
    "First let's select rows of the data to use as training and testing data. This recipe selects them randomly. \n",
    "* We need something that we can use both on data and target. \n",
    "* We know that data[i] <-> target[i]\n",
    "* We need something that preserves this. \n",
    "* If we choose indices, and apply the same selection to data and target, we preserve this correspondence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "selections = list(range(len(iris.data)))  # line numbers\n",
    "random.shuffle(selections) # randomize the order to eliminate sample bias\n",
    "# The type-2 irises are at the end, so sampling in the original order \n",
    "# would be a very poor sample. \n",
    "training_selections = selections[:130]  # first 130 are training data. \n",
    "testing_selections = selections[130:]  # last 20 are testing data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What this does\n",
    "* `random.shuffle` scrambles the numbers between 0 and 149. \n",
    "* `training_selections` is a list of the array offsets for a training set. \n",
    "* `testing_selections` is a list of the array offsets for a testing set. \n",
    "* These are disjoint lists with no elements in common. \n",
    "* These represent a random sampling of the data in the iris database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_selections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testing_selections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't change this cell; just run it. \n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('04-02-classification-notes.ok')\n",
    "ok.auth(inline=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create an `array` `training_features` that consists of the rows that match `training_selections`. Look up how to do it. Hint: `iris.data` is an `array`. Use row selection for `np.array`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your answer:\n",
    "training_features = ...\n",
    "training_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q01')  # check answer for sanity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create an `array` `training_targets` that consists of the targets corresponding to the selected training rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Your answer\n",
    "training_targets = ...\n",
    "training_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q02')  # check answer for sanity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Using the pattern above, train a kNN on the training data. Start with a new one `knn2` and just train on this. Hint: You need the data from parts 1 and 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer: \n",
    "knn2 = ...\n",
    "knn2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Put the test data into an `array` `testing_features`, repeating what you did for training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer: \n",
    "testing_features = ...\n",
    "testing_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade('q04')  # check answer for sanity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Run the predictor as above, but on the array `testing_features`. Put the result into `test_results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer: \n",
    "test_results = ...\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade('q05')  # check answer for sanity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Compute the expected outcomes and put them into the `array` `expected_results`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer: \n",
    "expected_results = ...\n",
    "expected_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade('q06')  # check answer for sanity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Count the number of identical answers between test_results and expected results and place the result into `correct_answers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer: \n",
    "correct_answers = ...\n",
    "correct_answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An afterword on cross-validation\n",
    "* If you got a perfect result, you're lucky. \n",
    "* Classification algorithms aren't perfect. \n",
    "* You can run it again to get an imperfect result. \n",
    "* Running the cross-validation multiple times gives one an idea of how accurate the classifier will be. \n",
    "* There are no \"correct\" answers to this. You just ran a random trial. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When you are done with this workbook, \n",
    "1. Ensure that the name of this notebook file is precisely 'Classification.ipynb'. That is what will be submitted to me for grading. \n",
    "2. Save and checkpoint that file.\n",
    "3. Change `ready` to `True in the script below. \n",
    "4. Run the script below to submit your workbook for grading. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ready = False  # change to True when ready to submit\n",
    "if not ready: \n",
    "    raise Exception(\"change ready to True when ready to submit\")\n",
    "_ = ok.submit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
